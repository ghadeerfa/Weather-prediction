# -*- coding: utf-8 -*-
"""Weather_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-kbkOINNTb6ru7sPiSBJfoG4jcPCQ033

# Weather Prediction using (Naive Bayes (NB),Logistic Regression (LR),Support Vector Machine (SVM),K-Nearest Neighbors (KNN),Artificial Neural Networks (ANN))

# 1- Import library
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib as plt
import seaborn as sns
import plotly.express as px
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

"""# 2- Read weather dataset"""

#importons le dataset
df=pd.read_csv('/content/drive/My Drive/seattle-weather.csv')

df.head()

"""# 3- Understand and Prepare the Data"""

print ("Rows     : " ,df.shape[0])
print ("Columns  : " ,df.shape[1])
print ("\nFeatures : \n" ,df.columns.tolist())
print ("\nMissing values :  ", df.isnull().sum().values.sum())
print ("\nUnique values :  \n",df.nunique())

# Select only numeric columns
numeric_df = df.select_dtypes(include=[float, int])

# Calculate correlation matrix for numeric columns
correlation_matrix = numeric_df.corr()

# Display the correlation matrix
print(correlation_matrix)

df["weather"].unique()

df.info()

df["weather"].unique()

# get unique value count in each columns
df.nunique()

df.count()

df.weather.value_counts()

df["date"]=pd.to_datetime(df["date"])

df.info()

"""# 4-Visualisation"""

fig = px.histogram(df, x="weather",text_auto=True ,color='weather',title='most weather state persent').update_xaxes(categoryorder='total descending')
fig.show()

fig = px.pie(df, names="weather",color='weather',title='the most weather percent  ')
fig.show()

fig = px.histogram(df, x='weather',y="precipitation",color='weather',histfunc="avg",text_auto=True, title='Average of precipitation in each weather state').update_xaxes(categoryorder='total descending')
fig.show()

fig = px.histogram(df, x='weather',y="temp_max",color='weather',histfunc="avg",text_auto=True, title='most average temprature per weather state').update_xaxes(categoryorder='total descending')
fig.show()

fig = px.histogram(df, x='weather',y="wind",color='weather',histfunc="avg",text_auto=True, title='wind average in each weather state').update_xaxes(categoryorder='total ascending')
fig.show()

"""# 5- Feature engineering and selection"""

# feature engineering and selection
x = df[['precipitation', 'temp_max','temp_min','wind']].copy()
y=df[['weather']].copy()
x.head()

"""## 6-Convert weather value to numerical value"""

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
# conver subject column to numirical value
df['weather']= labelencoder.fit_transform(df[['weather']].copy())
y=df[['weather']].copy()

"""# 7-Correlation Matrix"""

# the relationship between variables
sns.heatmap(df.corr(),cmap = 'Wistia', annot= True)

"""## 8-Split dateset with cross validation"""

from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(x,y, random_state = 33, test_size = 0.33)

from sklearn.neural_network import MLPClassifier

"""# 9-Build our algorithms"""

models = []
models.append(("SVM",SVC()))
models.append(("NB",GaussianNB()))
models.append(("KNN",KNeighborsClassifier()))
models.append(("dt",DecisionTreeClassifier()))
models.append(("LR",LogisticRegression()))
models.append(("ANN",MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)))

results = []
names = []
m=[]
for name,model in models:
    kfold = KFold(n_splits=10)
    cv_result = cross_val_score(model,X_train,Y_train, cv = kfold,scoring = "accuracy")
    names.append(name)
    results.append(cv_result)
for i in range(len(names)):
    m.append(results[i].mean())
    print('accurcy of ',names[i],':' ,results[i].mean())

"""# 10-Accurcy of different classification models histogram"""

accuracy = pd.DataFrame({'Algorithm': names,'accuracy': m })
fig = px.histogram(accuracy, x='Algorithm',y="accuracy",color='Algorithm',text_auto=True,
                   title='Accurcy of different classification models').update_xaxes(categoryorder='total descending')
fig.show()

"""# 11-Best Accuracy of Machine learning Algorithm is Naive Bayes for my dataset."""

X_train,X_test,Y_train,Y_test = train_test_split(x,y, random_state = 22, test_size = 0.3)
nb = GaussianNB()
nb.fit(X_train,Y_train)
predictions = nb.predict(X_test)
# accuracy of svm(evaluate accuracy)
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error
print("accuracy_score :",accuracy_score(Y_test,predictions))
print("MAE :", mean_absolute_error(Y_test,predictions))

"""# 12-Classification report and confusion_matrix"""

from sklearn.metrics import classification_report, confusion_matrix


print('\n')
print("Precision, Recall, F1")
print('\n')
CR=classification_report(Y_test,predictions)
print(CR)
print('\n')

print('\n')
print("Confusion Matrix")
print('\n')
CM=confusion_matrix(Y_test,predictions)
print(CM)

"""# 13-Predict new data entry"""

# entry shape ['precipitation', 'temp_max','temp_min','wind']
pred=nb.predict([[0,10,9,2]])

Interest_prediction=labelencoder.inverse_transform(pred)

print("weather Prediction is:",Interest_prediction)

